{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:30:56.928569Z",
     "start_time": "2023-11-26T23:30:54.733517Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import openai\n",
    "import argparse\n",
    "\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from instructor import patch\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.json import pydantic_encoder\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:30:56.949270Z",
     "start_time": "2023-11-26T23:30:56.940574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-sv', '--save_time'], dest='save_time', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Flag to add current time in filename.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #########################\n",
    "# Arguments\n",
    "# #########################\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Arguments\n",
    "parser.add_argument('-sn', '--story_name', type=str, default='those-that-live-longest')\n",
    "parser.add_argument('-st', '--story_type', type=str, default='txt')\n",
    "parser.add_argument('-sp', '--story_root', type=str, default='./scraping/flash-fiction-library/romance')\n",
    "parser.add_argument('-rp', '--result_root', type=str, default='./results/flash-fiction-library/romance')\n",
    "parser.add_argument('-is', '--instruction_root', type=str, default='./prompts/instructions')\n",
    "parser.add_argument('-mn', '--model_name', type=str, default='gpt-4-1106-preview')\n",
    "parser.add_argument('-mt', '--chunk_size', type=int, default=1500)\n",
    "parser.add_argument('-co', '--chunk_overlap', type=int, default=0)\n",
    "parser.add_argument('-la', '--language', type=str, default='Chinese')\n",
    "parser.add_argument('-sv', '--save_time', action='store_true',\n",
    "                    help='Flag to add current time in filename.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:42.484160Z",
     "start_time": "2023-11-26T22:35:42.479151Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Helper functions\n",
    "# #########################\n",
    "# Text Processeing\n",
    "def load_text(file_path):\n",
    "        \n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def save_text(text, file_path):\n",
    "        \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text + '\\n')\n",
    "\n",
    "\n",
    "def format_scene(storyboard_result):\n",
    "    \"\"\"\n",
    "    This is a temporary sol and would\n",
    "    be replace by Pydantic modules later.\n",
    "\n",
    "    storyboard_result (dict): a chain map reduce dict.\n",
    "    \"\"\"\n",
    "    # Initialize a string\n",
    "    text = ''\n",
    "\n",
    "    # Format the divide line\n",
    "    for i in storyboard_result['intermediate_steps']:\n",
    "        text += '\\n---\\n\\n' + i + '\\n'\n",
    "\n",
    "    # Format the number which was discarded in map reduce\n",
    "    scenes = text.split('[Scene]')\n",
    "    text = scenes[0]\n",
    "    for j, scene in enumerate(scenes[1:], start=1):\n",
    "        text += f'[Scene {j}]{scene}'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:42.769511Z",
     "start_time": "2023-11-26T22:35:42.765907Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Split the docs\n",
    "# #########################\n",
    "def get_split_docs(story_path: str='./story.txt', \n",
    "                   chunk_size: int=1500, \n",
    "                   chunk_overlap: int=0):\n",
    "    \"\"\"\n",
    "    Make stories to be splitted.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load with text loader\n",
    "    loader = TextLoader(story_path)\n",
    "    doc = loader.load()\n",
    "\n",
    "    # Split the story into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                                   chunk_overlap=chunk_overlap)\n",
    "    split_docs = text_splitter.split_documents(doc)    \n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:43.039314Z",
     "start_time": "2023-11-26T22:35:43.030436Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Get the results\n",
    "# #########################\n",
    "def get_summary_storyboard(model_name: str='gpt-4-1106-preview',\n",
    "                           summary_question_prompt_path: str='',\n",
    "                           summary_refine_prompt_path: str='',\n",
    "                           storyboard_map_prompt_path: str='',\n",
    "                           summary_save_path: str='',\n",
    "                           storyboard_save_path: str='',\n",
    "                           split_docs: tuple=None):\n",
    "    \n",
    "    ##### Get the summary #####\n",
    "    # Set the chat model\n",
    "    chat_model = ChatOpenAI(model_name=model_name)\n",
    "    \n",
    "    # Load the prompt\n",
    "    summary_question_prompt = load_text(summary_question_prompt_path)\n",
    "    summary_refine_prompt = load_text(summary_refine_prompt_path)\n",
    "\n",
    "    # Set the prompts\n",
    "    question_prompt = PromptTemplate.from_template(summary_question_prompt)\n",
    "    refine_prompt = PromptTemplate.from_template(summary_refine_prompt)\n",
    "\n",
    "    # Run the chain\n",
    "    summary_chain = load_summarize_chain(\n",
    "        llm=chat_model,\n",
    "        chain_type='refine',\n",
    "        question_prompt=question_prompt,\n",
    "        refine_prompt=refine_prompt,\n",
    "        return_intermediate_steps=True,\n",
    "        input_key='input_documents',\n",
    "        output_key='output_text',\n",
    "    )\n",
    "\n",
    "    # Get the results\n",
    "    print('Getting the summary for characters and environments.')\n",
    "    print('This may take a while as i am constantly refining results.')\n",
    "    summary_result = summary_chain({'input_documents': split_docs})\n",
    "    summary = summary_result['output_text']\n",
    "    \n",
    "    \n",
    "    ##### Get the storyboad #####\n",
    "    # Load the prompt\n",
    "    storyboard_map_prompt = load_text(storyboard_map_prompt_path)\n",
    "    \n",
    "    # Set the prompts\n",
    "    map_prompt = PromptTemplate.from_template(storyboard_map_prompt)\n",
    "    combine_prompt = PromptTemplate.from_template('Provide an overall summary of {text}.')\n",
    "\n",
    "    # Run the chain\n",
    "    storyboard_chain = load_summarize_chain(\n",
    "        llm=chat_model,\n",
    "        chain_type='map_reduce',\n",
    "        map_prompt=map_prompt,\n",
    "        combine_prompt=combine_prompt,\n",
    "        return_intermediate_steps=True,\n",
    "        input_key='input_documents'\n",
    "    )\n",
    "\n",
    "    # Get the results\n",
    "    print('Getting the storyboard script.')\n",
    "    print('i am faster this time since it is fine to be parallel here.')\n",
    "    storyboard_result = storyboard_chain(\n",
    "        {'input_documents': split_docs,\n",
    "         'summary': summary})\n",
    "    storyboard = format_scene(storyboard_result)\n",
    "\n",
    "    # Save them\n",
    "    print('All done!')\n",
    "    save_text(summary, summary_save_path)\n",
    "    save_text(storyboard, storyboard_save_path)\n",
    "    \n",
    "    return summary, storyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:43.274087Z",
     "start_time": "2023-11-26T22:35:43.267320Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Translate things\n",
    "# #########################\n",
    "def translate_summary_storyboard(model_name: str='gpt-4-1106-preview',\n",
    "                                 language: str='Chinese',\n",
    "                                 summary: str='',\n",
    "                                 storyboard: str=''):\n",
    "    \"\"\"\n",
    "    Translate the summary into the designated language.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the chat model\n",
    "    chat_model = ChatOpenAI(model_name=model_name)\n",
    "    \n",
    "    # Translate for SUMMARY\n",
    "    summary_translated = chat_model.predict(\n",
    "        f'Translate the following text in {language}: {summary}')\n",
    "    \n",
    "    # Translate for the STORYBOARD\n",
    "    # Below is a bit nasty\n",
    "    # We will update that with Pydantic to keep clean\n",
    "    def extract_all_scenes(text):\n",
    "        # Split the text by '---' to get the scenes\n",
    "        scenes = text.split('---')\n",
    "\n",
    "        # Remove empty strings and strip leading/trailing white spaces from each scene\n",
    "        scenes = [scene.strip() for scene in scenes if scene.strip()]\n",
    "\n",
    "        return scenes\n",
    "\n",
    "    # Extract all scenes using the revised function\n",
    "    scenes = extract_all_scenes(storyboard)\n",
    "    \n",
    "    # The helper function for scene translation\n",
    "    def translate_scene(scene):\n",
    "        translation_prompt = (f'Translate the following text in {language}: \\n'\n",
    "                              f'{scene}\\n\\n'\n",
    "                              'YOUR RESPONSE GOES HERE: \\n')\n",
    "        scene_translated = chat_model.predict(translation_prompt)\n",
    "        return scene_translated\n",
    "    \n",
    "    # List to hold translated scenes\n",
    "    storyboard_translated_list = []\n",
    "\n",
    "    # Using ThreadPoolExecutor to translate scenes in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        storyboard_translated_list = list(executor.map(translate_scene, scenes))  \n",
    "        \n",
    "    # Initialize a string\n",
    "    storyboard_translated = ''\n",
    "\n",
    "    # Format the divide line\n",
    "    for i in storyboard_translated_list:\n",
    "        storyboard_translated += '\\n---\\n\\n' + i + '\\n'\n",
    "\n",
    "    # Save them\n",
    "    save_text(summary_translated,\n",
    "              result_root / f'{story_name}{save_time}-summary-translated.txt')\n",
    "    save_text(storyboard_translated,\n",
    "              result_root / f'{story_name}{save_time}-storyboard-translated.txt')\n",
    "    \n",
    "    # Notify\n",
    "    print('All done!')\n",
    "    \n",
    "    return summary_translated, storyboard_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:43.935478Z",
     "start_time": "2023-11-26T22:35:43.930329Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Put everything together\n",
    "# #########################\n",
    "def parse_single_story(story_path: str='./story.txt', \n",
    "                       chunk_size: int=1500, \n",
    "                       chunk_overlap: int=0,\n",
    "                       model_name: str='gpt-4-1106-preview',\n",
    "                       summary_question_prompt_path: str='',\n",
    "                       summary_refine_prompt_path: str='',\n",
    "                       storyboard_map_prompt_path: str='',\n",
    "                       summary_save_path: str='',\n",
    "                       storyboard_save_path: str='',\n",
    "                       language: str='Chinese'):\n",
    "    \n",
    "    # Split stories into chunks\n",
    "    split_docs = get_split_docs(story_path, \n",
    "                                chunk_size, \n",
    "                                chunk_overlap)\n",
    "    \n",
    "    # Get and save the summary and the storyboard\n",
    "    summary, storyboard = get_summary_storyboard(model_name,\n",
    "                                                 summary_question_prompt_path,\n",
    "                                                 summary_refine_prompt_path,\n",
    "                                                 storyboard_map_prompt_path,\n",
    "                                                 summary_save_path,\n",
    "                                                 storyboard_save_path,\n",
    "                                                 split_docs)\n",
    "    \n",
    "    # Translate and save the resulted content\n",
    "    summary_, storyboard_ = None, None\n",
    "    \n",
    "    if language:\n",
    "        summary_, storyboard_ = translate_summary_storyboard(model_name,\n",
    "                                                            language,\n",
    "                                                            summary,\n",
    "                                                            storyboard)\n",
    "        \n",
    "    return summary, storyboard, summary_, storyboard_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:35:44.397417Z",
     "start_time": "2023-11-26T22:35:44.392224Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################\n",
    "# Set the paths\n",
    "# #########################\n",
    "# Parse the arguments\n",
    "p = parser.parse_args('')\n",
    "\n",
    "# Set the argument\n",
    "for key, value in vars(p).items():\n",
    "    globals()[key] = value\n",
    "\n",
    "# Configure the time to be added in the resulted filename\n",
    "save_time = datetime.now().strftime('%Y-%m-%d-%H-%M') if p.save_time else ''\n",
    "\n",
    "# Set the result root\n",
    "result_root = Path(result_root)\n",
    "if not os.path.exists(result_root): \n",
    "    os.makedirs(result_root)\n",
    "\n",
    "# Set the story path\n",
    "story_path = Path(story_root) / f'{story_name}.{story_type}'\n",
    "\n",
    "# Set the saving paths for summary and storyboard\n",
    "summary_save_path = result_root / f'{story_name}{save_time}-summary.txt'\n",
    "storyboard_save_path = result_root / f'{story_name}{save_time}-storyboard.txt'\n",
    "\n",
    "# Set the prompt paths for summary and storyboard\n",
    "summary_question_prompt_path = Path(instruction_root) / 'summary_question.txt'\n",
    "summary_refine_prompt_path = Path(instruction_root) / 'summary_refine.txt'\n",
    "storyboard_map_prompt_path = Path(instruction_root) / 'storyboard_map.txt'\n",
    "\n",
    "# The paths we feed in the single function includes:\n",
    "# story_path, summary_save_path, storyboard_save_path\n",
    "# and those paths for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T22:50:59.573583Z",
     "start_time": "2023-11-26T22:37:27.986222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the summary for characters and environments.\n",
      "This may take a while as i am constantly refining results.\n",
      "Getting the storyboard script.\n",
      "i am faster this time since it is fine to be parallel here.\n",
      "All done!\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# #########################\n",
    "# Run the main function\n",
    "# #########################\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    summary, storyboard, summary_, storyboard_ = parse_single_story(\n",
    "        story_path, \n",
    "        chunk_size, \n",
    "        chunk_overlap,\n",
    "        model_name,\n",
    "        summary_question_prompt_path,\n",
    "        summary_refine_prompt_path,\n",
    "        storyboard_map_prompt_path,\n",
    "        summary_save_path,\n",
    "        storyboard_save_path,\n",
    "        language)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game",
   "language": "python",
   "name": "game"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
